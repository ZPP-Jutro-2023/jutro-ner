title: "ZPP Bachelor's project."
description: "NER in a new pipeline (Named Entity Recognition) to work with medical documentation."
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "zpp-ner"
  wandb-project-name: "zpp-ner"
  lang: "pl"
  data: "all.jsonl"
  version: "0.0.0"
  # Set your GPU ID, -1 is CPU 0 is default GPU if you have 1 GPU
  gpu_id: 0
  # Vectors model for train-with-vectors
  vectors_model: "pl_core_news_lg"

  # Path to file with pretrained weights
  init_tok2vec: null #"pretrain/model999.bin"

  default_args: "--paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --gpu-id ${vars.gpu_id} --code scripts/functions.py --training.logger.project_name ${vars.wandb-project-name}"
  train_size: 0.8

  # Paths used for config creation
  base_cfg: "configs/base.cfg"
  extend_cfg: "configs/extend.cfg"
  output_cfg: "configs/output.cfg"

# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["assets", "corpus", "configs", "training", "scripts", "packages"]

assets:
  - dest: "assets/all.jsonl"
    description: "All annotated data"

# Workflows are sequences of commands (see below) executed in order. You can
# run them via "spacy project run [workflow]". If a commands's inputs/outputs
# haven't changed, it won't be re-run.
workflows:
  base:
    - convert
    - debug-data
    - train-base
    - evaluate-base
  vectors:
    - convert
    - debug-data
    - train-with-vec
    - evaluate-with-vec
  transformers:
    - convert
    - debug-data-trf
    - train-trf
    - evaluate-trf

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "import-doccano"
    help: "Export labeled data from doccano and unpack it in /assets"
    script:
      - "python scripts/import_dataset.py 4 assets http://zpp-doccano.herokuapp.com/"
      - "unzip assets/dataset.zip -d assets/"

  - name: "download-lg"
    help: "Download a spaCy model with pretrained vectors"
    script:
      - "python -m spacy download ${vars.vectors_model}"

  - name: "pretrain"
    help: "Pretrain the vectors."
    script:
      - "python -m spacy pretrain configs/config.cfg ./pretrain --paths.raw_text assets/${vars.data} --code scripts/functions.py --gpu-id ${vars.gpu_id}"
    deps:
      - "assets/${vars.data}"

  - name: "convert"
    help: "Convert the data to spaCy's binary format"
    script:
      - "python scripts/convert.py assets/${vars.data} corpus ${vars.train_size}"
    deps:
      - "assets/${vars.data}"
      - "scripts/convert.py"
    outputs:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"

  - name: "debug-data"
    help: "Analyze and validate training and development data."
    script: 
      - "python -m spacy debug data configs/config.cfg --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --code scripts/functions.py"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
  
  - name: "debug-data-trf"
    help: "Analyze and validate training and development data for transformer config."
    script: 
      - "python -m spacy debug data configs/config_trf.cfg --paths.train corpus/train.spacy --paths.dev corpus/dev.spacy --code scripts/functions.py"
    deps:
      - "corpus/train.spacy"
      - "corpus/dev.spacy"

  - name: "train-base"
    help: "Train the NER model"
    script:
      - "python -m spacy train configs/config.cfg --output training/base/ ${vars.default_args}  --paths.init_tok2vec ${vars.init_tok2vec}"
    deps:
      - "configs/config.cfg"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "scripts/functions.py"
    outputs:
      - "training/base/model-best"

  - name: "train-with-vec"
    help: "Train the NER model with vectors (bad, don't use)"
    script:
      - "python -m spacy train configs/config.cfg --output training/with-vec/ ${vars.default_args} --paths.vectors ${vars.vectors_model} --components.tok2vec.model.embed.include_static_vectors true  --paths.init_tok2vec ${vars.init_tok2vec}"
    deps:
      - "configs/config.cfg"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "scripts/functions.py"

    outputs:
      - "training/with-vec/model-best"

  - name: "train-trf"
    help: "Train the NER model with a transformer"
    script:
      - "python -m spacy train configs/config_trf.cfg --output training/trf/ ${vars.default_args}"
    deps:
      - "configs/config_trf.cfg"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
      - "scripts/functions.py"
    outputs:
      - "training/trf/model-best"

  - name: "evaluate-base"
    help: "Evaluate the base model and export metrics"
    script:
      - "python -m spacy evaluate training/base/model-best corpus/dev.spacy --output training/base/metrics.json"
    deps:
      - "corpus/dev.spacy"
      - "training/base/model-best"
    outputs:
      - "training/base/metrics.json"

  - name: "evaluate-with-vec"
    help: "Evaluate the model with vectors and export metrics"
    script:
      - "python -m spacy evaluate training/with-vec/model-best corpus/dev.spacy --output training/with-vec/metrics.json"
    deps:
      - "corpus/dev.spacy"
      - "training/with-vec/model-best"
    outputs:
      - "training/with-vec/metrics.json"

  - name: "evaluate-trf"
    help: "Evaluate the transformer model and export metrics"
    script:
      - "python -m spacy evaluate training/trf/model-best corpus/dev.spacy --output training/trf/metrics.json"
    deps:
      - "corpus/dev.spacy"
      - "training/trf/model-best"
    outputs:
      - "training/trf/metrics.json"

  # - name: package
  #   help: "Package the trained model as a pip package"
  #   script:
  #     - "python -m spacy package training/model-best packages --name ${vars.name} --version ${vars.version} --force"
  #   deps:
  #     - "training/model-best"
  #   outputs_no_cache:
  #     - "packages/${vars.lang}_${vars.name}-${vars.version}/dist/${vars.lang}_${vars.name}-${vars.version}.tar.gz"

  - name: visualize
    help: Visualize the model's output interactively using Streamlit
    script:
      - "streamlit run scripts/visualize_model.py training/with-vec/model-best,training/base/model-best,training/trf/model-best"
    deps:
      - "scripts/visualize_model.py"
      - "training/"
  - name: create-config
    help: "Create config files based on provided initial parameters (base-config) and non-default settings (extend-config)"
    script: 
      - "python scripts/create_config.py ${vars.base_cfg} ${vars.extend_cfg} ${vars.output_cfg}"
    deps:
      - "${vars.base_cfg}"
      - "${vars.extend_cfg}"
    outputs: 
      - "${vars.output_cfg}"

  - name:  wandb-sweep
    help: "Run customized training runs for hyperparameter search using [Weights & Biases Sweeps](https://docs.wandb.ai/guides/sweeps)"
    script:
      - "wandb sweep -p ${vars.wandb-project-name} scripts/sweep.yml"
    deps:
      - "configs/sweep_config.cfg"
      - "scripts/sweeps_using_config.py"
      - "corpus/train.spacy"
      - "corpus/dev.spacy"
